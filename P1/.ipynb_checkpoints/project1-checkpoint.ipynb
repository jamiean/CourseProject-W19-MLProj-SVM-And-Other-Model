{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname):\n",
    "    \"\"\"\n",
    "    Reads in a csv file and return a dataframe. A dataframe df is similar to dictionary.\n",
    "    You can access the label by calling df['label'], the content by df['content']\n",
    "    the rating by df['rating']\n",
    "    \"\"\"\n",
    "    return pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dictionary(df):\n",
    "    word_dict = {}\n",
    "    set_d = set()\n",
    "    for i in range(df.index.size):\n",
    "        str = df.loc[i][\"text\"].lower()\n",
    "        for c in string.punctuation:\n",
    "            str = str.replace(c, ' ')\n",
    "        set_d = set_d.union(set(str.split()))\n",
    "    set_d = list(set_d)\n",
    "    for i in range(len(set_d)):\n",
    "        word_dict[set_d[i]] = i\n",
    "    return word_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@jetsvm thanks, i will!\n",
      "@huimininternational will call. thank you!\n",
      "@huimininternational saved the day:) @expedia lost a costumer #huimininternational #makingthingseasy #feelbetter\n",
      "{'jetsvm': 0, 'thanks': 1, 'i': 2, 'will': 3, 'huimininternational': 4, 'call': 5, 'thank': 6, 'you': 7, 'saved': 8, 'the': 9, 'day': 10, 'expedia': 11, 'lost': 12, 'a': 13, 'costumer': 14, 'makingthingseasy': 15, 'feelbetter': 16}\n"
     ]
    }
   ],
   "source": [
    "fname = \"data/dataset.csv\"\n",
    "dataframe = load_data(fname)\n",
    "dataframe = dataframe[dataframe['label'] != 0]\n",
    "positiveDF = dataframe[dataframe['label'] == 1].copy()\n",
    "negativeDF = dataframe[dataframe['label'] == -1].copy()\n",
    "X_train = pd.concat([positiveDF[:500], negativeDF[:500]]).reset_index(drop=True).copy()\n",
    "    \n",
    "    \n",
    "dict = {}\n",
    "index = 0\n",
    "set_d = set()\n",
    "for i in range(3):\n",
    "    str = X_train.loc[i][\"text\"].lower()\n",
    "    print(str)\n",
    "    for c in string.punctuation:\n",
    "        str = str.replace(c, ' ')\n",
    "    for part in str.split():\n",
    "        if part not in dict:\n",
    "            dict[part] = index\n",
    "            index += 1\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_matrix(df, word_dict):\n",
    "    number_of_reviews = df.shape[0]\n",
    "    number_of_words = len(word_dict)\n",
    "    feature_matrix = np.zeros((number_of_reviews, number_of_words))\n",
    "    \n",
    "    for i in range(df.index.size):\n",
    "        str = df.loc[i][\"text\"].lower()\n",
    "        for c in string.punctuation:\n",
    "            str = str.replace(c, ' ')\n",
    "        for part in str.split():\n",
    "            if part in word_dict: feature_matrix[i][word_dict.get(part)] = 1\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_binary_data():\n",
    "    fname = \"data/dataset.csv\"\n",
    "    dataframe = load_data(fname)\n",
    "    dataframe = dataframe[dataframe['label'] != 0]\n",
    "    positiveDF = dataframe[dataframe['label'] == 1].copy()\n",
    "    negativeDF = dataframe[dataframe['label'] == -1].copy()\n",
    "    X_train = pd.concat([positiveDF[:500], negativeDF[:500]]).reset_index(drop=True).copy()\n",
    "    dictionary = extract_dictionary(X_train)\n",
    "    X_test = pd.concat([positiveDF[500:700], negativeDF[500:700]]).reset_index(drop=True).copy()\n",
    "    Y_train = X_train['label'].values.copy()\n",
    "    Y_test = X_test['label'].values.copy()\n",
    "    X_train = generate_feature_matrix(X_train, dictionary)\n",
    "    X_test = generate_feature_matrix(X_test, dictionary)\n",
    "    return (X_train, Y_train, X_test, Y_test, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d = 2850\n",
      "AVE = 15.624\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test, dictionary = get_split_binary_data()\n",
    "print(\"d =\",X_train.shape[1])\n",
    "\n",
    "count = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    count += np.count_nonzero(X_train[i])\n",
    "print(\"AVE =\", count/X_train.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABOVE IS PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([[0,0], [1,0], [2,0], [3,1],[4,1],[5,1],[6,1],[7,1],[8,1],[9,1] ])\n",
    "y = np.array([-1, -1, 1, 1, -1, 1, -1, -1,1 ,1])\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma='auto')\n",
    "metrics = 'Accuracy'\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "skf.get_n_splits(X, y)\n",
    "perform = 0\n",
    "\n",
    "for train_ind, test_ind in skf.split(X, y):\n",
    "    X_train = X[train_ind]\n",
    "    y_train = y[train_ind]\n",
    "    clf.fit(X_train,y_train)\n",
    "    X_test = X[test_ind]\n",
    "    if metrics == 'AUROC':\n",
    "        y_pred = clf.decision_function(X_test)\n",
    "    else:\n",
    "        y_pred = clf.predict(X_test)\n",
    "    y_true = y[test_ind]\n",
    "    perform += performance(y_true, y_pred, metrics)\n",
    "print(perform / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_performance(clf, X, y, k=5, metric=\"accuracy\"):\n",
    "    scores = []\n",
    "    skf = StratifiedKFold(k)\n",
    "    skf.get_n_splits(X, y)\n",
    "\n",
    "    for train_ind, test_ind in skf.split(X, y):\n",
    "        X_train = X[train_ind]\n",
    "        y_train = y[train_ind]\n",
    "        clf.fit(X_train,y_train)\n",
    "        X_test = X[test_ind]\n",
    "        if metric == 'AUROC':\n",
    "            y_pred = clf.decision_function(X_test)\n",
    "        else:\n",
    "            y_pred = clf.predict(X_test)\n",
    "        y_true = y[test_ind]\n",
    "        scores.append(performance(y_true, y_pred, metric))\n",
    "\n",
    "    #And return the average performance across all fold splits.\n",
    "    return np.array(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(y_true, y_pred, metrix = 'Accuracy'):\n",
    "    from sklearn import metrics\n",
    "    \n",
    "    # Accuracy = (FP + FN) / N\n",
    "    if (metrix == 'Accuracy'):\n",
    "        return metrics.accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Recall/Sensitivity = TP / (TP + FN)\n",
    "    elif (metrix == 'Sensitivity'):\n",
    "        return metrics.recall_score(y_true, y_pred)\n",
    "    \n",
    "    # Precision = TP / (TP + FP)\n",
    "    elif (metrix == 'Precision'):\n",
    "        return metrics.precision_score(y_true, y_pred)\n",
    "    \n",
    "    # F1-Score = 2 * Precision * Sensitivity / (Precision + Sensitivity)\n",
    "    elif (metrix == \"F1-Score\"):\n",
    "        return metrics.f1_score(y_true, y_pred)\n",
    "    \n",
    "    # AUROC\n",
    "    elif (metrix == \"AUROC\"):\n",
    "        return metrics.roc_auc_score(y_true, y_pred)\n",
    "    \n",
    "    #Specificity = TN / (TN + FP)\n",
    "    elif (metrix == \"Specificity\"):\n",
    "        TN, FP, FN, TP = metrics.confusion_matrix(y_true, y_pred).ravel()\n",
    "        return TN / (TN + FP)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3(a) END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_classifier(penalty='l2', c=1.0, degree=1, r=0.0, class_weight='balanced'):\n",
    "    \n",
    "    if penalty == 'l1': return LinearSVC(penalty = 'l1', dual = False, C = c, class_weight = class_weight, max_iter = 100000)\n",
    "    if degree == 1: return SVC(kernel='linear', C=c, class_weight=class_weight, degree = degree)\n",
    "    if degree == 2: return SVC(gamma = 'auto', kernel='poly', C=c, class_weight=class_weight, degree = degree, coef0 = r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_param_linear(X, y, k=5, metric=\"accuracy\", C_range = [], penalty='l2'):\n",
    "    \"\"\"\n",
    "    Sweeps different settings for the hyperparameter of a linear-kernel SVM,\n",
    "    calculating the k-fold CV performance for each setting on X, y.\n",
    "    Input:\n",
    "        X: (n,d) array of feature vectors, where n is the number of examples\n",
    "        and d is the number of features\n",
    "        y: (n,) array of binary labels {1,-1}\n",
    "        k: int specifying the number of folds (default=5)\n",
    "        metric: string specifying the performance metric (default='accuracy',\n",
    "             other options: 'f1-score', 'auroc', 'precision', 'sensitivity',\n",
    "             and 'specificity')\n",
    "        C_range: an array with C values to be searched over\n",
    "    Returns:\n",
    "        The parameter value for a linear-kernel SVM that maximizes the\n",
    "        average 5-fold CV performance.\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    #HINT: You should be using your cv_performance function here\n",
    "    #to evaluate the performance of each SVM\n",
    "    \n",
    "    max, max_val = 0, 0\n",
    "    for potential in C_range:\n",
    "        clf = select_classifier(c = potential, penalty = penalty)\n",
    "        cur = cv_performance(clf,X,y,k,metric)\n",
    "        if cur > max_val:\n",
    "            max = potential\n",
    "            max_val = cur\n",
    "        print(potential, \":\", cur)\n",
    "    print(max, max_val)\n",
    "    return max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(C)\n",
    "C_range = [10 ** x for x in range(-3, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8390000000000001\n",
      "0.1 0.8390000000000001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_param_linear(X_train,Y_train,5,\"Accuracy\", C_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.8377282080627986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_param_linear(X_train,Y_train,5,\"F1-Score\", C_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 0.92036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_param_linear(X_train,Y_train,5,\"AUROC\", C_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8396602879906849\n",
      "10 0.8412795192518695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_param_linear(X_train,Y_train,5,\"Precision\", C_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8380000000000001\n",
      "0.001 0.8640000000000001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_param_linear(X_train,Y_train,5,\"Sensitivity\", C_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8400000000000001\n",
      "10 0.844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_param_linear(X_train,Y_train,5,\"Specificity\", C_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuray = 0.8325\n",
      "F1-Score = 0.8295165394402036\n",
      "AUROC = 0.92055\n",
      "Precision = 0.844559585492228\n",
      "Sensitivity = 0.815\n",
      "Specificity = 0.85\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel=\"linear\", C=0.1, class_weight=\"balanced\")\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "Y_pred_AU = clf.decision_function(X_test)\n",
    "print(\"Accuray =\", performance(Y_test, clf.predict(X_test), 'Accuracy'))\n",
    "print(\"F1-Score =\", performance(Y_test, Y_pred, 'F1-Score'))\n",
    "print(\"AUROC =\", performance(Y_test, Y_pred_AU, 'AUROC'))\n",
    "print(\"Precision =\", performance(Y_test, Y_pred, 'Precision'))\n",
    "print(\"Sensitivity =\", performance(Y_test, Y_pred, 'Sensitivity'))\n",
    "print(\"Specificity =\", performance(Y_test, Y_pred, 'Specificity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weight(X,y,penalty,metric,C_range):\n",
    "    \"\"\"\n",
    "    Takes as input the training data X and labels y and plots the L0-norm\n",
    "    (number of nonzero elements) of the coefficients learned by a classifier\n",
    "    as a function of the C-values of the classifier.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Plotting the number of nonzero entries of the parameter vector as a function of C\")\n",
    "    norm0 = []\n",
    "\n",
    "    # TODO: Implement this part of the function\n",
    "    #Here, for each value of c in C_range, you should\n",
    "    #append to norm0 the L0-norm of the theta vector that is learned\n",
    "    #when fitting an L2- or L1-penalty, degree=1 SVM to the data (X, y)\n",
    "    for potential in C_range:\n",
    "        clf = select_classifier(c=potential)\n",
    "        clf.fit(X,y)\n",
    "        norm_c0 = 0\n",
    "        for num in clf.coef_[0]:\n",
    "            if num != 0: norm_c0 += 1\n",
    "        norm0.append(norm_c0)\n",
    "\n",
    "\n",
    "\n",
    "    #This code will plot your L0-norm as a function of c\n",
    "    plt.plot(C_range, norm0)\n",
    "    plt.xscale('log')\n",
    "    plt.legend(['L0-norm'])\n",
    "    plt.xlabel(\"Value of C\")\n",
    "    plt.ylabel(\"Norm of theta\")\n",
    "    plt.title('Norm-'+penalty+'_penalty.png')\n",
    "    plt.savefig('Norm-'+penalty+'_penalty.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the number of nonzero entries of the parameter vector as a function of C\n"
     ]
    }
   ],
   "source": [
    "C_range = [10 ** x for x in range(-3, 4)]\n",
    "plot_weight(X_train,Y_train,'L2','Accuracy', C_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delayed -0.5495052637207417\n",
      "great 0.7654231353985255\n",
      "good 0.5959079712992326\n",
      "thank 0.901084078877419\n",
      "hours -0.6157880744020268\n",
      "worst -0.5074326295539983\n",
      "due -0.5208214853103377\n",
      "thanks 0.9694530539313565\n"
     ]
    }
   ],
   "source": [
    "clf = select_classifier(c = 0.1)\n",
    "clf.fit(X_train,Y_train)\n",
    "coef = np.array(clf.coef_[0])\n",
    "large_4 = np.argpartition(coef, -4)[-4:]\n",
    "least_4 = np.argpartition(coef, 4)[:4]\n",
    "\n",
    "for key, value in dictionary.items():\n",
    "    for item in large_4:\n",
    "        if value == item:\n",
    "            print(key, coef[value])\n",
    "    for item in least_4:\n",
    "        if value == item:\n",
    "            print(key, coef[value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_param_quadratic(X, y, k=5, metric=\"accuracy\", param_range=[]):\n",
    "    max_c,max_r, max_val = 0, 0, 0\n",
    "    for potent_c, potent_r in param_range:\n",
    "        clf = select_classifier(c = potent_c, r = potent_r, degree = 2)\n",
    "        cur = cv_performance(clf,X,y,k,metric)\n",
    "        if cur > max_val:\n",
    "            max_c = potent_c\n",
    "            max_r = potent_r\n",
    "            max_val = cur\n",
    "    print(metric, \":\", max_c, max_r, max_val)\n",
    "    return [max_c, max_r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC : 1000 0.1 0.91776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1000, 0.1]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_range = []\n",
    "for i in range(-3,4):\n",
    "    for j in range (-3,4): param_range.append([10**i, 10**j])\n",
    "select_param_quadratic(X_train, Y_train, 5, \"AUROC\", param_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC : 605.6043276989294 0.18318442222293044 0.91798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[605.6043276989294, 0.18318442222293044]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_range = []\n",
    "c = np.random.uniform(-3,3,25)\n",
    "r = np.random.uniform(-3,3,25)\n",
    "for i in range(25): param_range.append([10 ** c[i],10 ** r[i]])\n",
    "select_param_quadratic(X_train, Y_train, 5, \"AUROC\", param_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 : 0.5\n",
      "0.01 : 0.79738\n",
      "0.1 : 0.9016299999999999\n",
      "1 : 0.90514\n",
      "100 : 0.9059399999999999\n",
      "1000 : 0.9213800000000001\n",
      "1000 0.9213800000000001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_param_linear(X_train, Y_train, 5, 'AUROC', C_range, 'l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_imbalanced_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-82d2b1453693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mIMB_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMB_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_imbalanced_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mIMB_test_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMB_test_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_imbalanced_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_imbalanced_data' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IMB_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-086138fd357d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMB_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMB_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMB_test_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY_pred_AU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMB_test_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuray =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperformance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMB_test_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'IMB_features' is not defined"
     ]
    }
   ],
   "source": [
    "clf = select_classifier(c = 0.01, class_weight = {-1:7, 1:3})\n",
    "clf.fit(IMB_features, IMB_labels)\n",
    "Y_pred = clf.predict(IMB_test_features)\n",
    "Y_pred_AU = clf.decision_function(IMB_test_features)\n",
    "print(\"Accuray =\", performance(IMB_test_labels, Y_pred,'Accuracy'))\n",
    "print(\"F1-Score =\", performance(IMB_test_labels, Y_pred,'F1-Score'))\n",
    "print(\"AUROC =\", performance(IMB_test_labels, Y_pred_AU, 'AUROC'))\n",
    "print(\"Precision =\", performance(IMB_test_labels, Y_pred, 'Precision'))\n",
    "print(\"Sensitivity =\", performance(IMB_test_labels, Y_pred, 'Sensitivity'))\n",
    "print(\"Specificity =\", performance(IMB_test_labels, Y_pred, 'Specificity'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
